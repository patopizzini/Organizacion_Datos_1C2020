{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMPORTACIÓN GENERAL DE LIBRERIAS Y VISUALIZACIÓN DE DATOS (matplotlib y seaborn)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as DT\n",
    "import warnings\n",
    "import descartes\n",
    "import geopandas as gpd\n",
    "import json\n",
    "import requests\n",
    "import geocoderimport re \n",
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "# SKLEARN.\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# RANDOM FOREST.\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from shapely.geometry import Point, Polygon\n",
    "from urllib.request import urlopen\n",
    "\n",
    "# XGBOOST.\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#NLTK: https://www.nltk.org\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from langdetect import detect\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "#WORDCLOUD\n",
    "from wordcloud import WordCloud\n",
    "from PIL import Image\n",
    "\n",
    "# CONFIGURACIÓN.\n",
    "%matplotlib inline\n",
    "plt.style.use('default')\n",
    "pd.options.display.float_format = '{:20,.2f}'.format\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set(style=\"whitegrid\") \n",
    "plt.rcParams['figure.figsize'] = (15, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Limpia puntuacion, quita también usuarios y hashtags (@ y #)\n",
    "def clean_tweet(words):\n",
    "    result = []\n",
    "    for word in words:\n",
    "        stripped_word = word.strip()\n",
    "        if ((stripped_word.isalnum() == True) and (not(stripped_word.isdigit()))):      \n",
    "            result.append(stripped_word)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def filtrarPalabras(miArray):\n",
    "    variable = ''\n",
    "    for key in miArray:\n",
    "         if '#' in str(key):\n",
    "            variable = variable + ' ' + str(key)\n",
    "    return variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importacion del archivo CSV de fuente\n",
    "#https://www.kaggle.com/c/nlp-getting-started\n",
    "tweets = pd.read_csv('data/train.csv')\n",
    "datos = pd.read_csv('data/train.csv')\n",
    "nlp = pd.read_csv('data/train.csv')\n",
    "\n",
    "#Vemos la estructura del dataframe, trayendo los primeros 5 registros\n",
    "tweets.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
