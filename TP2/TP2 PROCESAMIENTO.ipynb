{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMPORTACIÓN GENERAL DE LIBRERIAS.\n",
    "import re \n",
    "import sys\n",
    "import json\n",
    "import nltk\n",
    "import geocoder\n",
    "import requests\n",
    "import warnings\n",
    "import descartes\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "import datetime as DT\n",
    "import category_encoders as ce\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# SKLEARN.\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# RANDOM FOREST.\n",
    "from urllib.request import urlopen\n",
    "from shapely.geometry import Point, Polygon\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# XGBOOST.\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NLTK: https://www.nltk.org\n",
    "from langdetect import detect\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "#WORDCLOUD\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# CONFIGURACIÓN.\n",
    "%matplotlib inline\n",
    "plt.style.use('default')\n",
    "pd.options.display.float_format = '{:20,.2f}'.format\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set(style=\"whitegrid\") \n",
    "plt.rcParams['figure.figsize'] = (15, 10)\n",
    "np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from string import punctuation\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Limpia puntuacion, quita también usuarios y hashtags (@ y #)\n",
    "def clean_tweet(words):\n",
    "    result = []\n",
    "    for word in words:\n",
    "        stripped_word = word.strip()\n",
    "        if ((stripped_word.isalnum() == True) and (not(stripped_word.isdigit()))):      \n",
    "            result.append(stripped_word)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def filtrarPalabras(miArray):\n",
    "    variable = ''\n",
    "    for key in miArray:\n",
    "         if '#' in str(key):\n",
    "            variable = variable + ' ' + str(key)\n",
    "    return variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### =====================================================================\n",
    "### LECTURA DE CSV.\n",
    "### ====================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importacion del archivo CSV de fuente\n",
    "#https://www.kaggle.com/c/nlp-getting-started\n",
    "original_train = pd.read_csv('data/train.csv')\n",
    "original_test = pd.read_csv('data/test.csv')\n",
    "original_sample_submission = pd.read_csv('data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### =====================================================================\n",
    "### PROCESAMIENTO DE DATOS.\n",
    "### ====================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COMPLETAMOS LOS NULOS CON UN TEXTO: 'VACIO'\n",
    "original_train.fillna('vacio', inplace = True)\n",
    "original_test.fillna('vacio', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7613 entries, 0 to 7612\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        7613 non-null   int64 \n",
      " 1   keyword   7613 non-null   object\n",
      " 2   location  7613 non-null   object\n",
      " 3   text      7613 non-null   object\n",
      " 4   target    7613 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 297.5+ KB\n"
     ]
    }
   ],
   "source": [
    "original_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PASAMOS TODO A MINÚSCULAS (TRAIN).\n",
    "original_train['text'] = original_train['text'].str.lower()\n",
    "original_train['location'] = original_train['location'].str.lower()\n",
    "original_train['keyword'] = original_train['keyword'].str.lower()\n",
    "#PASAMOS TODO A MINÚSCULAS (TEST).\n",
    "original_test['text'] = original_test['text'].str.lower()\n",
    "original_test['location'] = original_test['location'].str.lower()\n",
    "original_test['keyword'] = original_test['keyword'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ==================================================\n",
    "## TRATAMIENTO INCLUYENDO STOP WORDS.\n",
    "## =================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LONGITUD DEL TWEET Y CANTIDAD DE PALABRAS (TRAIN).\n",
    "original_train['length'] = original_train['text'].str.len()\n",
    "original_train['totalwords'] = original_train['text'].str.split().str.len()\n",
    "original_train['words'] = original_train.text.str.strip().str.split()\n",
    "original_train['lenXword'] = (original_train['length'] / original_train['totalwords'])\n",
    "#LONGITUD DEL TWEET Y CANTIDAD DE PALABRAS (TEST).\n",
    "original_test['length'] = original_test['text'].str.len()\n",
    "original_test['totalwords'] = original_test['text'].str.split().str.len()\n",
    "original_test['words'] = original_test.text.str.strip().str.split()\n",
    "original_test['lenXword'] = (original_test['length'] / original_test['totalwords'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ARMANDO UNA LISTA DE PALABRAS QUE PUEDEN REPRESENTAR CATÁSTROFES (TRAIN & TEST).\n",
    "selected_words_singular=['fire','flood','inundate','earthquake','quake','deluge','euption','twister','tornado','hurricane', 'landslide','typhoon','wildfire','forest fire','drought','avalanche','urgent','important','danger','warrning','evacuation']\n",
    "selected_words_plural=['fires','floods', 'earthquakes','quakes','deluges','rashes','tornadoes','hurricanes', 'landslides','typhoons','wildfires','forest fires','droughts','avalanches']\n",
    "selected_words_other=['heat wave','died','flooding','flooded','damage','urgent','important','danger','warrning','help','evacuation']\n",
    "col_one_list = original_train['keyword'].tolist()\n",
    "selected_words = selected_words_singular + selected_words_plural + selected_words_other + col_one_list\n",
    "s = set(selected_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BUSCAMOS LAS COINCIDENCIAS CON PALABRAS CLAVES Y SEPARAMOS LOS HASHTAGS (TRAIN).\n",
    "original_train = original_train.assign(hashtags=[filtrarPalabras(el) for el in original_train.words])\n",
    "original_train = original_train.assign(matches=[len(set(el) & s) for el in original_train.words])\n",
    "#BUSCAMOS LAS COINCIDENCIAS CON PALABRAS CLAVES Y SEPARAMOS LOS HASHTAGS (TEST).\n",
    "original_test = original_test.assign(hashtags=[filtrarPalabras(el) for el in original_test.words])\n",
    "original_test = original_test.assign(matches=[len(set(el) & s) for el in original_test.words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONTAMOS LA CANTIDAD DE HASHTAGS (TRAIN).\n",
    "original_train['hashtagsCantidad'] = original_train['hashtags'].str.count('#')\n",
    "original_train['preguntas'] = original_train['text'].str.count('[!]') + original_train['text'].str.count('[?]')\n",
    "original_train['simbolos'] = original_train['text'].str.count('[!]') + original_train['text'].str.count('[?]') + original_train['text'].str.count('=') + original_train['text'].str.count('>')\n",
    "#CONTAMOS LA CANTIDAD DE HASHTAGS (TEST).\n",
    "original_test['hashtagsCantidad'] = original_test['hashtags'].str.count('#')\n",
    "original_test['preguntas'] = original_test['text'].str.count('[!]') + original_test['text'].str.count('[?]')\n",
    "original_test['simbolos'] = original_test['text'].str.count('[!]') + original_test['text'].str.count('[?]') + original_test['text'].str.count('=') + original_test['text'].str.count('>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MARCAMOS QUIENES USAN UBICACIÓN Y PALABRAS CLAVES (TRAIN).\n",
    "original_train['conUbicacion'] = 0\n",
    "original_train['conKeyword'] = 0\n",
    "original_train.loc[original_train['location'] != 'vacio', ['conUbicacion']] = 1\n",
    "original_train.loc[original_train['keyword'] != 'vacio', ['conKeyword']] = 1\n",
    "#MARCAMOS QUIENES USAN UBICACIÓN Y PALABRAS CLAVES (TEST).\n",
    "original_test['conUbicacion'] = 0\n",
    "original_test['conKeyword'] = 0\n",
    "original_test.loc[original_test['location'] != 'vacio', ['conUbicacion']] = 1\n",
    "original_test.loc[original_test['keyword'] != 'vacio', ['conKeyword']] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ==================================================\n",
    "## TRATAMIENTO QUITANDO LAS STOP WORDS.\n",
    "## =================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratamiento del set con nltk y nlpaug\n",
    "# NLTK\n",
    "# Sabiendo que todos los tweets son en idioma ingles, quitamos las stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "original_train['text'] =  original_train['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
    "original_test['text'] =  original_test['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PASAMOS A LA RAÍZ IDOMÁTICA DE LA PALABRA.\n",
    "stemmer = SnowballStemmer('english')\n",
    "original_train['text'] = original_train['text'].apply(lambda x:' '.join([stemmer.stem(y) for y in x.split()]))\n",
    "original_test['text'] = original_test['text'].apply(lambda x:' '.join([stemmer.stem(y) for y in x.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#QUITAMOS LOS NÚMEROS.\n",
    "original_train['text'] = original_train['text'].str.replace('\\d+', '')\n",
    "original_test['text'] = original_test['text'].str.replace('\\d+', '')\n",
    "original_train['text'] = original_train['text'].str.replace('vacio', '')\n",
    "original_test['text'] = original_test['text'].str.replace('vacio', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF-IDF\n",
    "original_train_Serie = original_train['text']\n",
    "original_train_DF = original_train_Serie.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>deed reason #earthquak may allah forgiv us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>forest fire near la rong sask. canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>resid ask shelter place notifi officers. evacu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>, peopl receiv #wildfir evacu order california</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>got sent photo rubi #alaska smoke #wildfir pou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0         deed reason #earthquak may allah forgiv us\n",
       "1              forest fire near la rong sask. canada\n",
       "2  resid ask shelter place notifi officers. evacu...\n",
       "3     , peopl receiv #wildfir evacu order california\n",
       "4  got sent photo rubi #alaska smoke #wildfir pou..."
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_train_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF-IDF\n",
    "original_train_Serie = original_train['text']\n",
    "original_train_DF = original_train_Serie.to_frame()\n",
    "\n",
    "tfidf = TfidfVectorizer(min_df=2,max_df=0.5, ngram_range=(1,3))\n",
    "features = tfidf.fit_transform(original_train_DF['text'])\n",
    "original_train_DF = pd.concat(\n",
    "    [\n",
    "        original_train_DF,\n",
    "        pd.DataFrame(\n",
    "            features.todense(),\n",
    "            columns=tfidf.get_feature_names()\n",
    "        )\n",
    "    ], axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF-IDF\n",
    "original_test_Serie = original_test['text']\n",
    "original_test_DF = original_test_Serie.to_frame()\n",
    "\n",
    "tfidf = TfidfVectorizer(min_df=2,max_df=0.75, ngram_range=(1,3))\n",
    "features = tfidf.fit_transform(original_test_DF['text'])\n",
    "original_test_DF = pd.concat(\n",
    "    [\n",
    "        original_test_DF,\n",
    "        pd.DataFrame(\n",
    "            features.todense(),\n",
    "            columns=tfidf.get_feature_names()\n",
    "        )\n",
    "    ], axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_train_DF = original_train.fillna(0)\n",
    "original_test_DF = original_test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7613 entries, 0 to 7612\n",
      "Columns: 16230 entries, text to ûó stori volga\n",
      "dtypes: float64(16229), object(1)\n",
      "memory usage: 942.7+ MB\n"
     ]
    }
   ],
   "source": [
    "original_train_DF.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-136-e1770aa76373>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcorr_col\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mcorr_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_correlation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_train_DF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.70\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-136-e1770aa76373>\u001b[0m in \u001b[0;36mget_correlation\u001b[0;34m(data, threshold)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcormat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcormat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m                 \u001b[0mcolname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcormat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                 \u001b[0mcorr_col\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/OrgaDatos/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1757\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1758\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1759\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1760\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/OrgaDatos/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_scalar\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2040\u001b[0m         \u001b[0;31m# a fast-path to scalar access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2041\u001b[0m         \u001b[0;31m# if not, raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2042\u001b[0;31m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2043\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2044\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/OrgaDatos/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, index, col, takeable)\u001b[0m\n\u001b[1;32m   2898\u001b[0m         \"\"\"\n\u001b[1;32m   2899\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2900\u001b[0;31m             \u001b[0mseries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iget_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2901\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_box_datetimelike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2902\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/OrgaDatos/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_iget_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   3595\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_iget_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3596\u001b[0m         \u001b[0;34m\"\"\"Return the cached item, item represents a positional indexer.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3597\u001b[0;31m         \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3598\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3599\u001b[0m             \u001b[0mlower\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/OrgaDatos/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_info_axis\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    489\u001b[0m         }\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_info_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def get_correlation(data, threshold):\n",
    "    corr_col = set()\n",
    "    cormat = data.corr()\n",
    "    for i in range(len(cormat.columns)):\n",
    "        for j in range(i):\n",
    "            if abs(cormat.iloc[i,j]) > threshold:\n",
    "                colname = cormat.columns[i]\n",
    "                corr_col.add(colname)\n",
    "    return corr_col\n",
    "\n",
    "corr_features = get_correlation(original_train_DF, 0.70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_train_DF = original_train_DF.drop(labels= corr_features, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LONGITUD DEL TWEET Y CANTIDAD DE PALABRAS (TRAIN).\n",
    "original_train['length_SW'] = original_train['text'].str.len()\n",
    "original_train['totalwords_SW'] = original_train['text'].str.split().str.len()\n",
    "original_train['lenXword_SW'] = (original_train['length_SW'] / original_train['totalwords_SW'])\n",
    "original_train['stopWords'] = (original_train['totalwords'] - original_train['totalwords_SW']) + 1\n",
    "original_train['totalXsw'] = (original_train['totalwords_SW'] / original_train['stopWords'])\n",
    "#LONGITUD DEL TWEET Y CANTIDAD DE PALABRAS (TEST).\n",
    "original_test['length_SW'] = original_test['text'].str.len()\n",
    "original_test['totalwords_SW'] = original_test['text'].str.split().str.len()\n",
    "original_test['lenXword_SW'] = (original_test['length_SW'] / original_test['totalwords_SW'])\n",
    "original_test['stopWords'] = (original_test['totalwords'] - original_test['totalwords_SW']) + 1\n",
    "original_test['totalXsw'] = (original_test['totalwords_SW'] / original_test['stopWords'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ==================================================\n",
    "## ENCODING\n",
    "## =================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7613 entries, 0 to 7612\n",
      "Data columns (total 29 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   id                7613 non-null   int64  \n",
      " 1   keyword_0         7613 non-null   int64  \n",
      " 2   keyword_1         7613 non-null   int64  \n",
      " 3   keyword_2         7613 non-null   int64  \n",
      " 4   keyword_3         7613 non-null   int64  \n",
      " 5   keyword_4         7613 non-null   int64  \n",
      " 6   keyword_5         7613 non-null   int64  \n",
      " 7   keyword_6         7613 non-null   int64  \n",
      " 8   keyword_7         7613 non-null   int64  \n",
      " 9   keyword_8         7613 non-null   int64  \n",
      " 10  location          7613 non-null   object \n",
      " 11  text              7613 non-null   object \n",
      " 12  target            7613 non-null   int64  \n",
      " 13  length            7613 non-null   int64  \n",
      " 14  totalwords        7613 non-null   int64  \n",
      " 15  words             7613 non-null   object \n",
      " 16  lenXword          7613 non-null   float64\n",
      " 17  hashtags          7613 non-null   object \n",
      " 18  matches           7613 non-null   int64  \n",
      " 19  hashtagsCantidad  7613 non-null   int64  \n",
      " 20  preguntas         7613 non-null   int64  \n",
      " 21  simbolos          7613 non-null   int64  \n",
      " 22  conUbicacion      7613 non-null   int64  \n",
      " 23  conKeyword        7613 non-null   int64  \n",
      " 24  length_SW         7613 non-null   int64  \n",
      " 25  totalwords_SW     7613 non-null   int64  \n",
      " 26  lenXword_SW       7613 non-null   float64\n",
      " 27  stopWords         7613 non-null   int64  \n",
      " 28  totalXsw          7613 non-null   float64\n",
      "dtypes: float64(3), int64(22), object(4)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "encoder = ce.BinaryEncoder(cols=['keyword'])\n",
    "original_train_ce = encoder.fit_transform(original_train)\n",
    "original_train_ce.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3263 entries, 0 to 3262\n",
      "Data columns (total 28 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   id                3263 non-null   int64  \n",
      " 1   keyword_0         3263 non-null   int64  \n",
      " 2   keyword_1         3263 non-null   int64  \n",
      " 3   keyword_2         3263 non-null   int64  \n",
      " 4   keyword_3         3263 non-null   int64  \n",
      " 5   keyword_4         3263 non-null   int64  \n",
      " 6   keyword_5         3263 non-null   int64  \n",
      " 7   keyword_6         3263 non-null   int64  \n",
      " 8   keyword_7         3263 non-null   int64  \n",
      " 9   keyword_8         3263 non-null   int64  \n",
      " 10  location          3263 non-null   object \n",
      " 11  text              3263 non-null   object \n",
      " 12  length            3263 non-null   int64  \n",
      " 13  totalwords        3263 non-null   int64  \n",
      " 14  words             3263 non-null   object \n",
      " 15  lenXword          3263 non-null   float64\n",
      " 16  hashtags          3263 non-null   object \n",
      " 17  matches           3263 non-null   int64  \n",
      " 18  hashtagsCantidad  3263 non-null   int64  \n",
      " 19  preguntas         3263 non-null   int64  \n",
      " 20  simbolos          3263 non-null   int64  \n",
      " 21  conUbicacion      3263 non-null   int64  \n",
      " 22  conKeyword        3263 non-null   int64  \n",
      " 23  length_SW         3263 non-null   int64  \n",
      " 24  totalwords_SW     3263 non-null   int64  \n",
      " 25  lenXword_SW       3263 non-null   float64\n",
      " 26  stopWords         3263 non-null   int64  \n",
      " 27  totalXsw          3263 non-null   float64\n",
      "dtypes: float64(3), int64(21), object(4)\n",
      "memory usage: 713.9+ KB\n"
     ]
    }
   ],
   "source": [
    "encoder = ce.BinaryEncoder(cols=['keyword'])\n",
    "original_test_ce = encoder.fit_transform(original_test)\n",
    "original_test_ce.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HOT ENCODING PARA KEYWORD (TRAIN).\n",
    "# dummies = pd.get_dummies(original_train['keyword'], drop_first=False)\n",
    "# original_train = pd.concat([original_train, dummies], axis=1)\n",
    "# original_train.drop('keyword', 1, inplace = True)\n",
    "\n",
    "#HOT ENCODING PARA KEYWORD (TEST).\n",
    "# dummies = pd.get_dummies(original_test['keyword'], drop_first=False)\n",
    "# original_test = pd.concat([original_test, dummies], axis=1)\n",
    "# original_test.drop('keyword', 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ==================================================\n",
    "## DEJAMOS SOLO LAS COLUMNAS NUMÉRICAS.\n",
    "## =================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ELIMINAMOS LAS COLUMNAS QUE NO SON NUMÉRICAS (TRAIN).\n",
    "original_train_ce.drop('text', 1, inplace = True)\n",
    "original_train_ce.drop('words', 1, inplace = True)\n",
    "original_train_ce.drop('location', 1, inplace = True)\n",
    "original_train_ce.drop('hashtags', 1, inplace = True)\n",
    "#ELIMINAMOS LAS COLUMNAS QUE NO SON NUMÉRICAS (TEST).\n",
    "original_test_ce.drop('text', 1, inplace = True)\n",
    "original_test_ce.drop('words', 1, inplace = True)\n",
    "original_test_ce.drop('location', 1, inplace = True)\n",
    "original_test_ce.drop('hashtags', 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### =====================================================================\n",
    "### RESGUARDAMOS LOS DATOS EN CSV.\n",
    "### ====================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword_0</th>\n",
       "      <th>keyword_1</th>\n",
       "      <th>keyword_2</th>\n",
       "      <th>keyword_3</th>\n",
       "      <th>keyword_4</th>\n",
       "      <th>keyword_5</th>\n",
       "      <th>keyword_6</th>\n",
       "      <th>keyword_7</th>\n",
       "      <th>keyword_8</th>\n",
       "      <th>...</th>\n",
       "      <th>hashtagsCantidad</th>\n",
       "      <th>preguntas</th>\n",
       "      <th>simbolos</th>\n",
       "      <th>conUbicacion</th>\n",
       "      <th>conKeyword</th>\n",
       "      <th>length_SW</th>\n",
       "      <th>totalwords_SW</th>\n",
       "      <th>lenXword_SW</th>\n",
       "      <th>stopWords</th>\n",
       "      <th>totalXsw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>7</td>\n",
       "      <td>6.43</td>\n",
       "      <td>7</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>7</td>\n",
       "      <td>5.43</td>\n",
       "      <td>1</td>\n",
       "      <td>7.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "      <td>11</td>\n",
       "      <td>8.27</td>\n",
       "      <td>12</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>7</td>\n",
       "      <td>8.71</td>\n",
       "      <td>2</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>9</td>\n",
       "      <td>6.33</td>\n",
       "      <td>8</td>\n",
       "      <td>1.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  keyword_0  keyword_1  keyword_2  keyword_3  keyword_4  keyword_5  \\\n",
       "0   1          0          0          0          0          0          0   \n",
       "1   4          0          0          0          0          0          0   \n",
       "2   5          0          0          0          0          0          0   \n",
       "3   6          0          0          0          0          0          0   \n",
       "4   7          0          0          0          0          0          0   \n",
       "\n",
       "   keyword_6  keyword_7  keyword_8  ...  hashtagsCantidad  preguntas  \\\n",
       "0          0          0          1  ...                 1          0   \n",
       "1          0          0          1  ...                 0          0   \n",
       "2          0          0          1  ...                 0          0   \n",
       "3          0          0          1  ...                 1          0   \n",
       "4          0          0          1  ...                 2          0   \n",
       "\n",
       "   simbolos  conUbicacion  conKeyword  length_SW  totalwords_SW  \\\n",
       "0         0             0           0         45              7   \n",
       "1         0             0           0         38              7   \n",
       "2         0             0           0         91             11   \n",
       "3         0             0           0         61              7   \n",
       "4         0             0           0         57              9   \n",
       "\n",
       "           lenXword_SW  stopWords             totalXsw  \n",
       "0                 6.43          7                 1.00  \n",
       "1                 5.43          1                 7.00  \n",
       "2                 8.27         12                 0.92  \n",
       "3                 8.71          2                 3.50  \n",
       "4                 6.33          8                 1.12  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vemos la estructura del dataframe TRAIN.\n",
    "original_train_ce.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7613 entries, 0 to 7612\n",
      "Data columns (total 25 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   id                7613 non-null   int64  \n",
      " 1   keyword_0         7613 non-null   int64  \n",
      " 2   keyword_1         7613 non-null   int64  \n",
      " 3   keyword_2         7613 non-null   int64  \n",
      " 4   keyword_3         7613 non-null   int64  \n",
      " 5   keyword_4         7613 non-null   int64  \n",
      " 6   keyword_5         7613 non-null   int64  \n",
      " 7   keyword_6         7613 non-null   int64  \n",
      " 8   keyword_7         7613 non-null   int64  \n",
      " 9   keyword_8         7613 non-null   int64  \n",
      " 10  target            7613 non-null   int64  \n",
      " 11  length            7613 non-null   int64  \n",
      " 12  totalwords        7613 non-null   int64  \n",
      " 13  lenXword          7613 non-null   float64\n",
      " 14  matches           7613 non-null   int64  \n",
      " 15  hashtagsCantidad  7613 non-null   int64  \n",
      " 16  preguntas         7613 non-null   int64  \n",
      " 17  simbolos          7613 non-null   int64  \n",
      " 18  conUbicacion      7613 non-null   int64  \n",
      " 19  conKeyword        7613 non-null   int64  \n",
      " 20  length_SW         7613 non-null   int64  \n",
      " 21  totalwords_SW     7613 non-null   int64  \n",
      " 22  lenXword_SW       7613 non-null   float64\n",
      " 23  stopWords         7613 non-null   int64  \n",
      " 24  totalXsw          7613 non-null   float64\n",
      "dtypes: float64(3), int64(22)\n",
      "memory usage: 1.5 MB\n"
     ]
    }
   ],
   "source": [
    "original_train_ce.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword_0</th>\n",
       "      <th>keyword_1</th>\n",
       "      <th>keyword_2</th>\n",
       "      <th>keyword_3</th>\n",
       "      <th>keyword_4</th>\n",
       "      <th>keyword_5</th>\n",
       "      <th>keyword_6</th>\n",
       "      <th>keyword_7</th>\n",
       "      <th>keyword_8</th>\n",
       "      <th>...</th>\n",
       "      <th>hashtagsCantidad</th>\n",
       "      <th>preguntas</th>\n",
       "      <th>simbolos</th>\n",
       "      <th>conUbicacion</th>\n",
       "      <th>conKeyword</th>\n",
       "      <th>length_SW</th>\n",
       "      <th>totalwords_SW</th>\n",
       "      <th>lenXword_SW</th>\n",
       "      <th>stopWords</th>\n",
       "      <th>totalXsw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>6.75</td>\n",
       "      <td>3</td>\n",
       "      <td>1.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>7</td>\n",
       "      <td>7.86</td>\n",
       "      <td>3</td>\n",
       "      <td>2.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>10</td>\n",
       "      <td>6.30</td>\n",
       "      <td>10</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>10.00</td>\n",
       "      <td>1</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>6</td>\n",
       "      <td>6.33</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  keyword_0  keyword_1  keyword_2  keyword_3  keyword_4  keyword_5  \\\n",
       "0   0          0          0          0          0          0          0   \n",
       "1   2          0          0          0          0          0          0   \n",
       "2   3          0          0          0          0          0          0   \n",
       "3   9          0          0          0          0          0          0   \n",
       "4  11          0          0          0          0          0          0   \n",
       "\n",
       "   keyword_6  keyword_7  keyword_8  ...  hashtagsCantidad  preguntas  \\\n",
       "0          0          0          1  ...                 0          0   \n",
       "1          0          0          1  ...                 1          0   \n",
       "2          0          0          1  ...                 0          0   \n",
       "3          0          0          1  ...                 2          0   \n",
       "4          0          0          1  ...                 0          0   \n",
       "\n",
       "   simbolos  conUbicacion  conKeyword  length_SW  totalwords_SW  \\\n",
       "0         0             0           0         27              4   \n",
       "1         0             0           0         55              7   \n",
       "2         0             0           0         63             10   \n",
       "3         0             0           0         40              4   \n",
       "4         0             0           0         38              6   \n",
       "\n",
       "           lenXword_SW  stopWords             totalXsw  \n",
       "0                 6.75          3                 1.33  \n",
       "1                 7.86          3                 2.33  \n",
       "2                 6.30         10                 1.00  \n",
       "3                10.00          1                 4.00  \n",
       "4                 6.33          3                 2.00  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vemos la estructura del dataframe TEST.\n",
    "original_test_ce.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3263 entries, 0 to 3262\n",
      "Data columns (total 24 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   id                3263 non-null   int64  \n",
      " 1   keyword_0         3263 non-null   int64  \n",
      " 2   keyword_1         3263 non-null   int64  \n",
      " 3   keyword_2         3263 non-null   int64  \n",
      " 4   keyword_3         3263 non-null   int64  \n",
      " 5   keyword_4         3263 non-null   int64  \n",
      " 6   keyword_5         3263 non-null   int64  \n",
      " 7   keyword_6         3263 non-null   int64  \n",
      " 8   keyword_7         3263 non-null   int64  \n",
      " 9   keyword_8         3263 non-null   int64  \n",
      " 10  length            3263 non-null   int64  \n",
      " 11  totalwords        3263 non-null   int64  \n",
      " 12  lenXword          3263 non-null   float64\n",
      " 13  matches           3263 non-null   int64  \n",
      " 14  hashtagsCantidad  3263 non-null   int64  \n",
      " 15  preguntas         3263 non-null   int64  \n",
      " 16  simbolos          3263 non-null   int64  \n",
      " 17  conUbicacion      3263 non-null   int64  \n",
      " 18  conKeyword        3263 non-null   int64  \n",
      " 19  length_SW         3263 non-null   int64  \n",
      " 20  totalwords_SW     3263 non-null   int64  \n",
      " 21  lenXword_SW       3263 non-null   float64\n",
      " 22  stopWords         3263 non-null   int64  \n",
      " 23  totalXsw          3263 non-null   float64\n",
      "dtypes: float64(3), int64(21)\n",
      "memory usage: 611.9 KB\n"
     ]
    }
   ],
   "source": [
    "original_test_ce.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target\n",
       "0   0       0\n",
       "1   2       0\n",
       "2   3       0\n",
       "3   9       0\n",
       "4  11       0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vemos la estructura del dataframe SAMPLE_SUBMISSION.\n",
    "original_sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_train_ce.to_csv('data/processed/original_train.csv',index=False)\n",
    "original_test_ce.to_csv('data/processed/original_test.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### =====================================================================\n",
    "### FIN.\n",
    "### ====================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
